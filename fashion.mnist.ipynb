{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing packages\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup mps for training on apple Silicon\n",
    "\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup training data\n",
    "\n",
    "data_train = datasets.FashionMNIST(\n",
    "    root=\"data\", \n",
    "    train=True, \n",
    "    download=True, \n",
    "    transform=ToTensor(), \n",
    "    target_transform=None \n",
    ")\n",
    "\n",
    "## Setup testing data\n",
    "\n",
    "data_test = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False, \n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualising one data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Break the data down into batches for training\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "dataloader_train = DataLoader(data_train,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              shuffle=True)\n",
    "\n",
    "dataloader_test = DataLoader(data_test,\n",
    "                             batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 784])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(iter(dataloader_train))\n",
    "nn.Flatten()(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating the model\n",
    "\n",
    "class FashionMNISTModel(nn.Module):\n",
    "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
    "        super().__init__()\n",
    "        self.layer_stack = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=input_shape, out_features=hidden_units),\n",
    "            nn.Linear(in_features=hidden_units, out_features=output_shape))\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return self.layer_stack(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating the model for our target device\n",
    "\n",
    "model_0 = FashionMNISTModel(input_shape=784,\n",
    "                            hidden_units=10,\n",
    "                            output_shape=10).to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting up loss function and optimizer\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(params=model_0.parameters(),\n",
    "                            lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "195f11fd030146f5bd92eb681161a6ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "train loss: 0.5900816917419434 || test loss: 0.49177682399749756\n",
      "epoch: 1\n",
      "train loss: 0.4746129512786865 || test loss: 0.5016408562660217\n",
      "epoch: 2\n",
      "train loss: 0.45413026213645935 || test loss: 0.48987898230552673\n"
     ]
    }
   ],
   "source": [
    "## Training and testing loop\n",
    "\n",
    "epochs = 3\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"epoch: {epoch}\")\n",
    "    loss_train_cum = 0;\n",
    "    model_0.train()\n",
    "\n",
    "    for batch, (X, y) in enumerate(dataloader_train):\n",
    "\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        logits_train = model_0(X)\n",
    "\n",
    "        loss_train = loss_fn(logits_train, y)\n",
    "\n",
    "        loss_train_cum += loss_train\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss_train.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    loss_train_per_batch = loss_train_cum / len(dataloader_train)\n",
    "\n",
    "    # Testing\n",
    "    model_0.eval()\n",
    "    loss_test = 0\n",
    "    with torch.inference_mode():\n",
    "        for (X, y) in dataloader_test:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            logits_test = model_0(X)\n",
    "            loss_test += loss_fn(logits_test, y)\n",
    "        loss_test_per_batch = loss_test / len(dataloader_test)\n",
    "    \n",
    "    print(f\"train loss: {loss_train_per_batch} || test loss: {loss_test_per_batch}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
